{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphlab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7a0740057403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;31m## For machine learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mgraphlab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named graphlab"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "## General libraries\n",
    "from itertools import ifilter\n",
    "import numpy as np\n",
    "import inspect\n",
    "import csv\n",
    "\n",
    "## For machine learning\n",
    "import graphlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/tomarnoldussen/Documents/vse/data/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/tomarnoldussen/Documents/vse/data/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.046733 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.046733 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,str,int,int,str,str,str,str,str,str,str,str,str,str,str,str,int,int,int,int,str,str,str,str,str,int,str,str,str,str,str,str,str,int,str,int,int,int,str,str,str,str,int,int,int,int,int,int,int,int,int,int,str,int,str,int,str,str,int,str,int,int,str,str,str,int,int,int,int,int,int,str,str,str,int,int,int,str,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/tomarnoldussen/Documents/vse/data/train.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/tomarnoldussen/Documents/vse/data/train.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1460 lines in 0.021244 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1460 lines in 0.021244 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/tomarnoldussen/Documents/vse/data/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/tomarnoldussen/Documents/vse/data/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.0309 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.0309 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,str,int,int,str,str,str,str,str,str,str,str,str,str,str,str,int,int,int,int,str,str,str,str,str,int,str,str,str,str,str,str,str,int,str,int,int,int,str,str,str,str,int,int,int,int,int,int,int,int,int,int,str,int,str,int,str,str,int,str,int,int,str,str,str,int,int,int,int,int,int,str,str,str,int,int,int,str,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/tomarnoldussen/Documents/vse/data/test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/tomarnoldussen/Documents/vse/data/test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1459 lines in 0.022479 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1459 lines in 0.022479 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all data sources\n",
    "trainData = graphlab.SFrame('data/train.csv')\n",
    "testData = graphlab.SFrame('data/test.csv')\n",
    "\n",
    "# trainData.print_rows(num_rows=10, num_columns=81)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class loadModels():\n",
    "    def tomsModel(self):\n",
    "        #Name of your model\n",
    "        \"\"\"Tom's model\"\"\"\n",
    "        \n",
    "        sqft_model = graphlab.linear_regression.create(trainData, target='SalePrice', features=['GrLivArea'],validation_set=None,verbose=False)\n",
    "        return sqft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to evaluate specific models\n",
    "def evaluateModels(models, data):\n",
    "    f = models()\n",
    "    attrs = (getattr(f, name) for name in dir(f))\n",
    "    methods = ifilter(inspect.ismethod, attrs)\n",
    "    tableColumns = [\"Model\", \"Max Error\", \"RMSE\"]\n",
    "    tableData = [np.empty( shape=(3, 3) )]\n",
    "    i = 0\n",
    "    for method in methods:\n",
    "        try:\n",
    "            test = method().evaluate(data)\n",
    "            tableData[i] = [method.__doc__, test['max_error'], test['rmse']]\n",
    "            i +=i \n",
    "        except TypeError:\n",
    "            # Can't handle methods with required arguments.\n",
    "            print \"error\"\n",
    "            pass\n",
    "    row_format =\"{:>15}\" * (len(tableColumns) + 1)\n",
    "    print row_format.format(\"\", *tableColumns)\n",
    "    for model, row in zip(tableColumns, tableData):\n",
    "        print row_format.format(model, *row)\n",
    "        \n",
    "\n",
    "# Function to create a CSV for testing at Kaggle competition\n",
    "def generateCSVForKaggle(model, data, tag):\n",
    "\n",
    "    with open('output.csv', 'w') as outcsv: \n",
    "        writer = csv.writer(outcsv, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL, lineterminator='\\n')\n",
    "        writer.writerow(['Id', 'SalePrice'])\n",
    "        for i in xrange(0, len(data)):\n",
    "            dataId = data[i]['Id']\n",
    "            dataPrediction = model().tomsModel().predict(data[i])\n",
    "            writer.writerow([dataId, dataPrediction[0]])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Model      Max Error           RMSE\n",
      "          Model    Tom's model  462970.281756  56034.3039805\n"
     ]
    }
   ],
   "source": [
    "# Call evaluation function on all models\n",
    "\n",
    "evaluateModels(loadModels, trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generateCSVForKaggle(loadModels, testData, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
